{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9SStKf4G0V5H"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.util import img_as_ubyte\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import io\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYxHegIM0Z4i",
    "outputId": "23f4c990-0d3b-4ade-db2b-49704367b8f5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This is an example of generating mixed features for one machine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "h9DATQwS0ivD"
   },
   "outputs": [],
   "source": [
    "class MimiiDataset(Dataset):\n",
    "    def __init__(self,audio_dir, n_fft = 1024, win_length = 1024,\n",
    "                 hop_length = 512,power = 2,n_mels = 128,pad_mode = 'reflect',\n",
    "                 sr = 16000,center = True,norm = None):\n",
    "      \n",
    "        super(MimiiDataset, self).__init__()\n",
    "        self.audio_dir = audio_dir\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.power = power\n",
    "        self.pad_mode = pad_mode\n",
    "        self.sr = sr\n",
    "        self.center = center\n",
    "        self.norm = norm\n",
    "\n",
    "    def get_files(self):\n",
    "       return self.train_files, self.test_files\n",
    "    \n",
    "    def get_data(self,device, id):\n",
    "        \n",
    "        self.train_files, self.train_labels = self._train_file_list(device, id)\n",
    "        self.test_files, self.test_labels = self._test_file_list(device, id)\n",
    "        \n",
    "        self.train_data = self.get_audios(self.train_files)\n",
    "        self.test_data = self.get_audios(self.test_files)\n",
    "        \n",
    "        return self.train_data, self.test_data, self.train_labels, self.test_labels\n",
    "    \n",
    "    def _train_file_list(self, device, id):\n",
    "        query = os.path.abspath(\n",
    "            f\"{self.audio_dir}/{device}/train/normal_id_0{id}*.wav\"\n",
    "        )\n",
    "        train_normal_files = sorted(glob.glob(query))\n",
    "        train_normal_labels = np.zeros(len(train_normal_files))\n",
    "        \n",
    "        query = os.path.abspath(\n",
    "                f\"{self.audio_dir}/{device}/train/anomaly_id_0{id}*.wav\"\n",
    "            )\n",
    "        train_anomaly_files = sorted(glob.glob(query))\n",
    "        train_anomaly_labels = np.ones(len(train_anomaly_files))\n",
    "        \n",
    "        train_file_list = np.concatenate((train_normal_files, train_anomaly_files), axis=0)\n",
    "        train_labels = np.concatenate((train_normal_labels, train_anomaly_labels), axis=0)\n",
    "        \n",
    "        return train_file_list, train_labels\n",
    "    \n",
    "    def _test_file_list(self, device, id):     \n",
    "        query = os.path.abspath(\n",
    "            f\"{self.audio_dir}/{device}/test/normal_id_0{id}*.wav\"\n",
    "            )\n",
    "        test_normal_files = sorted(glob.glob(query))\n",
    "        test_normal_labels = np.zeros(len(test_normal_files))\n",
    "        \n",
    "        query = os.path.abspath(\n",
    "            f\"{self.audio_dir}/{device}/test/anomaly_id_0{id}*.wav\"\n",
    "            )\n",
    "        test_anomaly_files = sorted(glob.glob(query))\n",
    "        test_anomaly_labels = np.ones(len(test_anomaly_files))\n",
    "        \n",
    "        test_file_list = np.concatenate((test_normal_files, \n",
    "                                          test_anomaly_files), axis=0)\n",
    "        test_labels = np.concatenate((test_normal_labels,\n",
    "                                      test_anomaly_labels), axis=0)\n",
    "          \n",
    "        return test_file_list, test_labels\n",
    "\n",
    "    def normalize(self,tensor):\n",
    "        tensor_minusmean = tensor - tensor.mean()\n",
    "        return tensor_minusmean/np.absolute(tensor_minusmean).max()\n",
    "\n",
    "    def make0min(self,tensornd):\n",
    "        tensor = tensornd.numpy()\n",
    "        res = np.where(tensor == 0, 1E-19 , tensor)\n",
    "        return torch.from_numpy(res)\n",
    "\n",
    "    def spectrogrameToImage(self,specgram):\n",
    "        # specgram = torchaudio.transforms.MelSpectrogram(n_fft=1024, win_length=1024, \n",
    "        #                                                 hop_length=512, power=2, \n",
    "        #                                                 normalized=True, n_mels=128)(waveform )\n",
    "        specgram= self.make0min(specgram)\n",
    "        specgram = specgram.log2()[0,:,:].numpy()\n",
    "        \n",
    "        tr2image = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "        specgram= self.normalize(specgram)\n",
    "        # specgram = img_as_ubyte(specgram)\n",
    "        specgramImage = tr2image(specgram)\n",
    "        return specgramImage\n",
    "\n",
    "    def get_logmelspectrogram(self, waveform):\n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "          n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_length,\n",
    "          power=self.power,n_mels=self.n_mels,pad_mode=self.pad_mode,sr=self.sr,\n",
    "          center=self.center,norm=self.norm,htk=True,\n",
    "          y = waveform.numpy()\n",
    "        )\n",
    "\n",
    "        logmelspec = librosa.power_to_db(melspec)\n",
    "\n",
    "        return logmelspec\n",
    "\n",
    "    def get_melspectrogram(self,waveform):\n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "            n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_length,\n",
    "            power=self.power,n_mels=self.n_mels,pad_mode=self.pad_mode,sr=self.sr,\n",
    "            center=self.center,norm=self.norm,htk=True,\n",
    "            y = waveform.numpy()\n",
    "        )\n",
    "\n",
    "        return melspec\n",
    "    \n",
    "    def get_mfcc(self,waveform):\n",
    "        mfcc = librosa.feature.mfcc(    \n",
    "            n_fft=self.n_fft, win_length=self.win_length, \n",
    "            hop_length=self.hop_length,pad_mode=self.pad_mode,sr=self.sr,\n",
    "            center=self.center,norm=self.norm,n_mfcc=40,\n",
    "            y = waveform.numpy()\n",
    "        )\n",
    "\n",
    "        return mfcc\n",
    "\n",
    "    def get_chroma_stft(self,waveform):\n",
    "        stft = librosa.feature.chroma_stft(\n",
    "            n_fft=self.n_fft, win_length=self.win_length, \n",
    "            hop_length=self.hop_length,pad_mode=self.pad_mode,sr=self.sr,\n",
    "            center=self.center,norm=self.norm,n_chroma=12,\n",
    "            y=waveform.numpy()\n",
    "        )\n",
    "\n",
    "        return stft\n",
    "\n",
    "    def get_spectral_contrast(self,waveform):\n",
    "        spec_contrast = librosa.feature.spectral_contrast(    \n",
    "            n_fft=self.n_fft, win_length=self.win_length,center=self.center,\n",
    "            hop_length=self.hop_length,pad_mode=self.pad_mode,sr=self.sr,\n",
    "            y = waveform.numpy()\n",
    "        )\n",
    "\n",
    "        return spec_contrast\n",
    "    \n",
    "    def get_tonnetz(self,waveform):\n",
    "        harmonic = librosa.effects.harmonic(waveform.numpy())\n",
    "        tonnetz = librosa.feature.tonnetz(y=harmonic,sr=self.sr)\n",
    "\n",
    "        return tonnetz\n",
    "\n",
    "    def get_audios(self, file_list):\n",
    "        data = []\n",
    "        for i in range(len(file_list)):\n",
    "          y, sr = torchaudio.load(file_list[i])  \n",
    "          data.append(y)\n",
    "\n",
    "        return data\n",
    "    def _derive_data(self, file_list):\n",
    "        train_data = []\n",
    "        test_data = []\n",
    "        train_mode = True\n",
    "        for file_list in [self.train_files, self.test_files]:\n",
    "          tr2tensor = transforms.Compose([transforms.PILToTensor()])\n",
    "          data = []\n",
    "          for j in range(len(file_list)):\n",
    "            y, sr = torchaudio.load(file_list[j])  \n",
    "            spec = self.get_melspectrogram(y)\n",
    "            spec = self.spectrogrameToImage(spec)\n",
    "            spec = spec.convert('RGB')\n",
    "            vectors = tr2tensor(spec)\n",
    "            if train_mode:     \n",
    "              train_data.append(vectors)\n",
    "            else:\n",
    "              test_data.append(vectors)\n",
    "            \n",
    "          train_mode = False\n",
    "                \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = MimiiDataset('/content/drive/MyDrive/mimii')"
   ],
   "metadata": {
    "id": "9VYW7t52lxzn"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def mean_mfccs(wave_list):\n",
    "  data = []\n",
    "  for wave in wave_list:\n",
    "    mfcc = np.mean(dataset.get_mfcc(wave)[0], axis = 1)\n",
    "    data.append(mfcc)\n",
    "  \n",
    "  return data\n",
    "\n",
    "def mean_stfts(wave_list):\n",
    "  data = []\n",
    "  for wave in wave_list:\n",
    "    stft = np.mean(dataset.get_chroma_stft(wave)[0], axis = 1)\n",
    "    data.append(stft)\n",
    "  \n",
    "  return data\n",
    "\n",
    "def mean_melspecs(wave_list):\n",
    "  data = []\n",
    "  for wave in wave_list:\n",
    "    melspec = np.mean(dataset.get_melspectrogram(wave)[0], axis = 1)\n",
    "    data.append(melspec)\n",
    "  \n",
    "  return data\n",
    "\n",
    "def mean_spec_contrasts(wave_list):\n",
    "  data = []\n",
    "  for wave in wave_list:\n",
    "    spec_contrast = np.mean(dataset.get_spectral_contrast(wave)[0], axis = 1)\n",
    "    data.append(spec_contrast)\n",
    "  \n",
    "  return data\n",
    "  \n",
    "def mean_tonnetzs(wave_list):\n",
    "  data = []\n",
    "  for wave in wave_list:\n",
    "    tonnetz = np.mean(dataset.get_tonnetz(wave)[0], axis = 1)\n",
    "    data.append(tonnetz)\n",
    "  \n",
    "  return data"
   ],
   "metadata": {
    "id": "quhoMJUJsqyU"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train1, df_test1, y_train1, y_test1 = dataset.get_data('ToyConveyor', 1)"
   ],
   "metadata": {
    "id": "C70jD80rrQJ_"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_melspecs, test_melspecs = mean_melspecs(df_train1), mean_melspecs(df_test1)\n",
    "train_mfccs, test_mfccs = mean_mfccs(df_train1), mean_mfccs(df_test1)\n",
    "train_stfts, test_stfts = mean_stfts(df_train1), mean_stfts(df_test1)\n",
    "train_spec_contrasts, test_spec_contrasts = mean_spec_contrasts(df_train1), mean_spec_contrasts(df_test1)\n",
    "train_tonnetzs, test_tonnetzs = mean_tonnetzs(df_train1), mean_tonnetzs(df_test1)"
   ],
   "metadata": {
    "id": "JIbH42KBln8M"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_mixed_f(melspecs,mfccs,stfts,spec_contrasts,tonnetzs):\n",
    "  mixed_f = []\n",
    "\n",
    "  for i in range(len(melspecs)):\n",
    "\n",
    "    mf = np.concatenate((melspecs[i],mfccs[i],stfts[i],\n",
    "                          spec_contrasts[i],tonnetzs[i])).tolist()\n",
    "\n",
    "    mixed_f.append(mf)\n",
    "\n",
    "\n",
    "  mixed_f = torch.FloatTensor(mixed_f)\n",
    "  return mixed_f"
   ],
   "metadata": {
    "id": "5NAMxzpLrYJm"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_mixed_f = make_mixed_f(train_melspecs,train_mfccs,train_stfts,train_spec_contrasts,train_tonnetzs)\n",
    "test_mixed_f = make_mixed_f(test_melspecs,test_mfccs,test_stfts,test_spec_contrasts,test_tonnetzs)"
   ],
   "metadata": {
    "id": "_F3OqWhMl29R"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(train_mixed_f, '/content/drive/MyDrive/mixed_features/y_tr_toyconveyor1.pt')\n",
    "torch.save(test_mixed_f, '/content/drive/MyDrive/mixed_features/y_ts_toyconveyor1.pt')"
   ],
   "metadata": {
    "id": "sw7SAvRzrmqe"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
