{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9SStKf4G0V5H"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.util import img_as_ubyte\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import io\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XtxbKLZq5KX",
    "outputId": "5b531e35-f2a7-4f6d-e102-5ed6dcad02e9"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYxHegIM0Z4i",
    "outputId": "8ca23d0a-c4d8-44e7-8b0d-808247298a23"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "h9DATQwS0ivD"
   },
   "outputs": [],
   "source": [
    "class MimiiDataset(Dataset):\n",
    "    def __init__(self,audio_dir, n_fft = 1024, win_length = 1024,\n",
    "                 hop_length = 512,power = 2,n_mels = 128,pad_mode = 'reflect',\n",
    "                 sr = 16000,center = True,norm = None):\n",
    "      \n",
    "        super(MimiiDataset, self).__init__()\n",
    "        self.audio_dir = audio_dir\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.power = power\n",
    "        self.pad_mode = pad_mode\n",
    "        self.sr = sr\n",
    "        self.center = center\n",
    "        self.norm = norm\n",
    "\n",
    "    def get_files(self):\n",
    "       return self.train_files, self.test_files\n",
    "    \n",
    "    def get_data(self,device, id):\n",
    "        \n",
    "        self.train_files, self.train_labels = self._train_file_list(device, id)\n",
    "        self.test_files, self.test_labels = self._test_file_list(device, id)\n",
    "        \n",
    "        self.train_data = self.get_audios(self.train_files)\n",
    "        self.test_data = self.get_audios(self.test_files)\n",
    "        \n",
    "        return self.train_data, self.test_data, self.train_labels, self.test_labels\n",
    "    \n",
    "    def _train_file_list(self, device, id):\n",
    "        query = os.path.abspath(\n",
    "            f\"{self.audio_dir}/{device}/train/normal_id_0{id}*.wav\"\n",
    "        )\n",
    "        train_normal_files = sorted(glob.glob(query))\n",
    "        train_normal_labels = np.zeros(len(train_normal_files))\n",
    "        \n",
    "        query = os.path.abspath(\n",
    "                f\"{self.audio_dir}/{device}/train/anomaly_id_0{id}*.wav\"\n",
    "            )\n",
    "        train_anomaly_files = sorted(glob.glob(query))\n",
    "        train_anomaly_labels = np.ones(len(train_anomaly_files))\n",
    "        \n",
    "        train_file_list = np.concatenate((train_normal_files, train_anomaly_files), axis=0)\n",
    "        train_labels = np.concatenate((train_normal_labels, train_anomaly_labels), axis=0)\n",
    "        \n",
    "        return train_file_list, train_labels\n",
    "    \n",
    "    def _test_file_list(self, device, id):     \n",
    "        query = os.path.abspath(\n",
    "            f\"{self.audio_dir}/{device}/test/normal_id_0{id}*.wav\"\n",
    "            )\n",
    "        test_normal_files = sorted(glob.glob(query))\n",
    "        test_normal_labels = np.zeros(len(test_normal_files))\n",
    "        \n",
    "        query = os.path.abspath(\n",
    "            f\"{self.audio_dir}/{device}/test/anomaly_id_0{id}*.wav\"\n",
    "            )\n",
    "        test_anomaly_files = sorted(glob.glob(query))\n",
    "        test_anomaly_labels = np.ones(len(test_anomaly_files))\n",
    "        \n",
    "        test_file_list = np.concatenate((test_normal_files, \n",
    "                                          test_anomaly_files), axis=0)\n",
    "        test_labels = np.concatenate((test_normal_labels,\n",
    "                                      test_anomaly_labels), axis=0)\n",
    "          \n",
    "        return test_file_list, test_labels\n",
    "\n",
    "    def normalize(self,tensor):\n",
    "        tensor_minusmean = tensor - tensor.mean()\n",
    "        return tensor_minusmean/np.absolute(tensor_minusmean).max()\n",
    "\n",
    "    def make0min(self,tensornd):\n",
    "        tensor = tensornd.numpy()\n",
    "        res = np.where(tensor == 0, 1E-19 , tensor)\n",
    "        return torch.from_numpy(res)\n",
    "\n",
    "    def spectrogrameToImage(self,specgram):\n",
    "        # specgram = torchaudio.transforms.MelSpectrogram(n_fft=1024, win_length=1024, \n",
    "        #                                                 hop_length=512, power=2, \n",
    "        #                                                 normalized=True, n_mels=128)(waveform )\n",
    "        specgram= self.make0min(specgram)\n",
    "        specgram = specgram.log2()[0,:,:].numpy()\n",
    "        \n",
    "        tr2image = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "        specgram= self.normalize(specgram)\n",
    "        # specgram = img_as_ubyte(specgram)\n",
    "        specgramImage = tr2image(specgram)\n",
    "        return specgramImage\n",
    "\n",
    "    def get_logmelspectrogram(self, waveform):\n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "          n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_length,\n",
    "          power=self.power,n_mels=self.n_mels,pad_mode=self.pad_mode,sr=self.sr,\n",
    "          center=self.center,norm=self.norm,htk=True,\n",
    "          y = waveform.numpy()\n",
    "        )\n",
    "\n",
    "        logmelspec = librosa.power_to_db(melspec)\n",
    "\n",
    "        return logmelspec\n",
    "\n",
    "    def get_melspectrogram(self,waveform):\n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "            n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_length,\n",
    "            power=self.power,n_mels=self.n_mels,pad_mode=self.pad_mode,sr=self.sr,\n",
    "            center=self.center,norm=self.norm,htk=True,\n",
    "            y = waveform.numpy()\n",
    "        )\n",
    "\n",
    "        return melspec\n",
    "    \n",
    "    def get_mfcc(self,waveform):\n",
    "        mfcc = librosa.feature.mfcc(    \n",
    "            n_fft=self.n_fft, win_length=self.win_length, \n",
    "            hop_length=self.hop_length,pad_mode=self.pad_mode,sr=self.sr,\n",
    "            center=self.center,norm=self.norm,n_mfcc=40,\n",
    "            y = waveform.numpy()\n",
    "        )\n",
    "\n",
    "        return mfcc\n",
    "\n",
    "    def get_chroma_stft(self,waveform):\n",
    "        stft = librosa.feature.chroma_stft(\n",
    "            n_fft=self.n_fft, win_length=self.win_length, \n",
    "            hop_length=self.hop_length,pad_mode=self.pad_mode,sr=self.sr,\n",
    "            center=self.center,norm=self.norm,n_chroma=12,\n",
    "            y=waveform.numpy()\n",
    "        )\n",
    "\n",
    "        return stft\n",
    "\n",
    "    def get_spectral_contrast(self,waveform):\n",
    "        spec_contrast = librosa.feature.spectral_contrast(    \n",
    "            n_fft=self.n_fft, win_length=self.win_length,center=self.center,\n",
    "            hop_length=self.hop_length,pad_mode=self.pad_mode,sr=self.sr,\n",
    "            y = waveform.numpy()\n",
    "        )\n",
    "\n",
    "        return spec_contrast\n",
    "    \n",
    "    def get_tonnetz(self,waveform):\n",
    "        harmonic = librosa.effects.harmonic(waveform.numpy())\n",
    "        tonnetz = librosa.feature.tonnetz(y=harmonic,sr=self.sr)\n",
    "\n",
    "        return tonnetz\n",
    "\n",
    "    def get_audios(self, file_list):\n",
    "        data = []\n",
    "        for i in range(len(file_list)):\n",
    "          y, sr = torchaudio.load(file_list[i])  \n",
    "          data.append(y)\n",
    "\n",
    "        return data\n",
    "    def _derive_data(self, file_list):\n",
    "        train_data = []\n",
    "        test_data = []\n",
    "        train_mode = True\n",
    "        for file_list in [self.train_files, self.test_files]:\n",
    "          tr2tensor = transforms.Compose([transforms.PILToTensor()])\n",
    "          data = []\n",
    "          for j in range(len(file_list)):\n",
    "            y, sr = torchaudio.load(file_list[j])  \n",
    "            spec = self.get_melspectrogram(y)\n",
    "            spec = self.spectrogrameToImage(spec)\n",
    "            spec = spec.convert('RGB')\n",
    "            vectors = tr2tensor(spec)\n",
    "            if train_mode:     \n",
    "              train_data.append(vectors)\n",
    "            else:\n",
    "              test_data.append(vectors)\n",
    "            \n",
    "          train_mode = False\n",
    "                \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "S96soeIc0o13"
   },
   "outputs": [],
   "source": [
    "dataset = MimiiDataset('/content/drive/MyDrive/mimii')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_train, y_test = torch.load('/content/drive/MyDrive/labels/y_tr_pump6.pt'), torch.load('/content/drive/MyDrive/labels/y_ts_pump6.pt')"
   ],
   "metadata": {
    "id": "siHf9ch8vFoI"
   },
   "execution_count": 103,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_mf, test_mf = torch.load('/content/drive/MyDrive/mixed_features/train_mf_pump6.pt'), torch.load('/content/drive/MyDrive/mixed_features/test_mf_pump6.pt')"
   ],
   "metadata": {
    "id": "WiRjmJe_yH6u"
   },
   "execution_count": 94,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "jWMPVGu1qiEq"
   },
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_mf, batch_size=64, shuffle = True)\n",
    "test_data = DataLoader(test_mf, batch_size = 64, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "vNTBTRe6qnBq"
   },
   "outputs": [],
   "source": [
    "class UNet_FC(nn.Module):\n",
    "\n",
    "  def __init__(self, in_features):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.bn = nn.BatchNorm1d(128)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    self.fc0 = nn.Linear(in_features=in_features,out_features=in_features)\n",
    "\n",
    "    # encoder\n",
    "    self.fc1 = nn.Linear(in_features=in_features, out_features=128)\n",
    "    self.fc2 = nn.Linear(in_features=128,out_features=128)\n",
    "    self.fc3 = nn.Linear(in_features=128, out_features=128)\n",
    "    self.fc4 = nn.Linear(in_features=128, out_features=128)\n",
    "    self.fc5 = nn.Linear(in_features=128, out_features=8)\n",
    "\n",
    "    # decoder\n",
    "    self.fc6 = nn.Linear(in_features=8, out_features=128)\n",
    "    self.fc7 = nn.Linear(in_features=128*2, out_features=128)\n",
    "    self.fc8 = nn.Linear(in_features=128*2, out_features=128)\n",
    "    self.fc9 = nn.Linear(in_features=128*2, out_features=128)\n",
    "\n",
    "    self.out = nn.Linear(in_features=128*2, out_features=in_features)\n",
    "\n",
    "  def forward(self, x):\n",
    "    input = self.fc0(x)\n",
    "\n",
    "    x1 = self.relu(self.bn(self.fc1(input)))\n",
    "    x2 = self.relu(self.bn(self.fc2(x1)))\n",
    "    x3 = self.relu(self.bn(self.fc3(x2)))\n",
    "    x4 = self.relu(self.bn(self.fc4(x3)))\n",
    "    x5 = self.relu(self.fc5(x4))\n",
    "\n",
    "    xy = [x5, x4, x3, x2, x1]\n",
    "\n",
    "    x6 = self.relu(self.fc6(xy[0]))\n",
    "    con1 = torch.cat((x6,xy[1]), 1) \n",
    "    x7 = self.relu(self.bn(self.fc7(con1)))\n",
    "    con2 = torch.cat((x7,xy[2]), 1)\n",
    "    x8 = self.relu(self.bn(self.fc8(con2)))\n",
    "    con3 = torch.cat((x8,xy[3]), 1)\n",
    "    x9 = self.relu(self.bn(self.fc9(con3)))\n",
    "    con4 = torch.cat((x9,xy[4]), 1)\n",
    "\n",
    "    x10 = self.out(con4)\n",
    "\n",
    "    return x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "ZfgcBtQ3qn5l"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, data_tr, data_val, scheduler = None,\n",
    "          epochs = 3000, device = 'cpu'):\n",
    "    # X_val, Y_val = next(iter(data_val))\n",
    "    losses = []\n",
    "    prev_avg_loss = 100000\n",
    "    for epoch in range(epochs):\n",
    "        train_avg_loss = 0\n",
    "        test_avg_loss = 0\n",
    "        # model.train()  # train mode\n",
    "        for batch in data_tr:\n",
    "          # data to device\n",
    "          batch = batch.to(device)\n",
    "          # set parameter gradients to zero\n",
    "          optimizer.zero_grad()\n",
    "          # forward\n",
    "          # print(Y_batch.shape)\n",
    "          predictions = model(batch)\n",
    "          loss = criterion(predictions, batch)\n",
    "          loss.backward() # backward-pass\n",
    "          optimizer.step()  # update weights\n",
    "          # calculate loss to show the user\n",
    "          if scheduler:\n",
    "            scheduler.step(loss)\n",
    "          train_avg_loss += loss / len(data_tr)\n",
    "\n",
    "        # model.eval()\n",
    "        for batch in data_val:\n",
    "          with torch.no_grad():\n",
    "            preds = model(batch.to(device)).cpu()\n",
    "            loss = criterion(preds,batch)\n",
    "            test_avg_loss += loss / len(data_val)\n",
    "                    \n",
    "        losses.append(train_avg_loss.item())\n",
    "        if (epoch+1)%100 == 0:\n",
    "          print(\"{}/{} train_loss: {} test_loss:{}\".format(epoch+1, epochs, train_avg_loss, test_avg_loss))\n",
    "        # if test_avg_loss < 70:\n",
    "        #   break\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "ptkVTF55quOL"
   },
   "outputs": [],
   "source": [
    "unet = UNet_FC(in_features=193).to(device)\n",
    "optimizer = Adam(params = unet.parameters(), lr = 10e-3)\n",
    "# optimizer = Adam(params = unet.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, \n",
    "                                                       min_lr=10e-4, mode = 'min',\n",
    "                                                       patience = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkfmYl9oXhcB",
    "outputId": "dc62323c-c734-4181-a083-c738930d0e02"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100/3000 train_loss: 638.5532836914062 test_loss:1506.1083984375\n",
      "200/3000 train_loss: 484.2655029296875 test_loss:1436.390625\n",
      "300/3000 train_loss: 296.45458984375 test_loss:1272.830078125\n",
      "400/3000 train_loss: 212.6880340576172 test_loss:1196.794189453125\n",
      "500/3000 train_loss: 189.54568481445312 test_loss:1036.7138671875\n",
      "600/3000 train_loss: 133.39291381835938 test_loss:1030.0650634765625\n",
      "700/3000 train_loss: 112.66610717773438 test_loss:872.436279296875\n",
      "800/3000 train_loss: 101.91997528076172 test_loss:892.1138305664062\n",
      "900/3000 train_loss: 83.21659088134766 test_loss:800.1068115234375\n",
      "1000/3000 train_loss: 74.90437316894531 test_loss:868.642822265625\n",
      "1100/3000 train_loss: 71.12741088867188 test_loss:817.7181396484375\n",
      "1200/3000 train_loss: 67.22933959960938 test_loss:846.176513671875\n",
      "1300/3000 train_loss: 54.591732025146484 test_loss:824.5293579101562\n",
      "1400/3000 train_loss: 49.42818832397461 test_loss:826.33154296875\n",
      "1500/3000 train_loss: 48.00450897216797 test_loss:844.0997314453125\n",
      "1600/3000 train_loss: 50.54262924194336 test_loss:800.8279418945312\n",
      "1700/3000 train_loss: 51.07139587402344 test_loss:781.8063354492188\n",
      "1800/3000 train_loss: 47.462989807128906 test_loss:787.79638671875\n",
      "1900/3000 train_loss: 43.328800201416016 test_loss:777.1176147460938\n",
      "2000/3000 train_loss: 39.1593017578125 test_loss:795.407958984375\n",
      "2100/3000 train_loss: 36.89868927001953 test_loss:805.6582641601562\n",
      "2200/3000 train_loss: 39.81501007080078 test_loss:807.5621948242188\n",
      "2300/3000 train_loss: 43.19016647338867 test_loss:780.0242919921875\n",
      "2400/3000 train_loss: 34.37915802001953 test_loss:767.580078125\n",
      "2500/3000 train_loss: 32.798858642578125 test_loss:829.4112548828125\n",
      "2600/3000 train_loss: 32.83007049560547 test_loss:805.4448852539062\n",
      "2700/3000 train_loss: 33.273895263671875 test_loss:815.39892578125\n",
      "2800/3000 train_loss: 28.758892059326172 test_loss:794.41943359375\n",
      "2900/3000 train_loss: 37.742332458496094 test_loss:800.3237915039062\n",
      "3000/3000 train_loss: 30.390979766845703 test_loss:820.3259887695312\n"
     ]
    }
   ],
   "source": [
    "losses= train(model = unet, optimizer = optimizer, criterion=criterion, data_tr=train_data,\n",
    "               data_val = test_data, scheduler = scheduler, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ew7_F0-q7aL",
    "outputId": "1de85ec9-0750-41c1-f118-fd6709dc64ba"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(820.3260)"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "avg_loss = 0\n",
    "# unet.eval()\n",
    "# unet.train()\n",
    "preds = []\n",
    "i = 0\n",
    "test_anomaly_losses = []\n",
    "test_normal_losses = []\n",
    "test_losses = []\n",
    "# test_real = y_test_fan0.tolist()\n",
    "# y_test_fan0 = y_test_fan0.tolist()\n",
    "for batch in test_data:\n",
    "  with torch.no_grad():\n",
    "    # unet.train()\n",
    "    predictions = unet(batch.to(device)).cpu()\n",
    "    preds.append(predictions)\n",
    "  loss = criterion(predictions, batch.cpu())\n",
    "  for j in range(len(predictions)):\n",
    "    if int(y_test[i]) == 1:\n",
    "      test_anomaly_losses.append(float(criterion(predictions[j], batch[j])))\n",
    "    else:\n",
    "      test_normal_losses.append(float(criterion(predictions[j], batch[j])))\n",
    "    i += 1\n",
    "    test_losses.append(criterion(predictions[j], batch[j]))\n",
    "  # print(loss)\n",
    "  # print(loss)\n",
    "  avg_loss += loss / len(test_data)\n",
    "# avg_loss\n",
    "\n",
    "avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpDKorrRso9o",
    "outputId": "ed95d906-1a00-4c90-fc42-9d777d59e863"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1381.0546112808527, 80.56352132797241)"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "sum(test_anomaly_losses)/len(test_anomaly_losses) , sum(test_normal_losses)/len(test_normal_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LEvbZKYuh7J",
    "outputId": "054683ea-2241-4dfb-a570-994b872901b3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8872549019607843\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "vals = np.arange(50, 1000, 0.5).tolist()\n",
    "for threshold in vals:\n",
    "  preds = []\n",
    "  for j in range(len(test_losses)):\n",
    "    if test_losses[j] > threshold:\n",
    "      preds.append(1)\n",
    "    else:\n",
    "      preds.append(0)\n",
    "  \n",
    "  results.append(roc_auc_score(y_test,preds))\n",
    "\n",
    "print(max(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaSSqG8SbAw2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
