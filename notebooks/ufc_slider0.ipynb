{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9SStKf4G0V5H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "import torchaudio\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.util import img_as_ubyte\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import io\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XtxbKLZq5KX",
        "outputId": "8a37e895-6306-48d2-c10c-c18501261351"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYxHegIM0Z4i",
        "outputId": "1a35bf7e-76eb-4682-94b5-ed17dbb1e6cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h9DATQwS0ivD"
      },
      "outputs": [],
      "source": [
        "class MimiiDataset(Dataset):\n",
        "    def __init__(self,audio_dir, n_fft = 1024, win_length = 1024,\n",
        "                 hop_length = 512,power = 2,n_mels = 128,pad_mode = 'reflect',\n",
        "                 sr = 16000,center = True,norm = None):\n",
        "      \n",
        "        super(MimiiDataset, self).__init__()\n",
        "        self.audio_dir = audio_dir\n",
        "        self.n_mels = n_mels\n",
        "        self.n_fft = n_fft\n",
        "        self.win_length = win_length\n",
        "        self.hop_length = hop_length\n",
        "        self.power = power\n",
        "        self.pad_mode = pad_mode\n",
        "        self.sr = sr\n",
        "        self.center = center\n",
        "        self.norm = norm\n",
        "\n",
        "    def get_files(self):\n",
        "       return self.train_files, self.test_files\n",
        "    \n",
        "    def get_data(self,device, id):\n",
        "        \n",
        "        self.train_files, self.train_labels = self._train_file_list(device, id)\n",
        "        self.test_files, self.test_labels = self._test_file_list(device, id)\n",
        "        \n",
        "        self.train_data = self.get_audios(self.train_files)\n",
        "        self.test_data = self.get_audios(self.test_files)\n",
        "        \n",
        "        return self.train_data, self.test_data, self.train_labels, self.test_labels\n",
        "    \n",
        "    def _train_file_list(self, device, id):\n",
        "        query = os.path.abspath(\n",
        "            f\"{self.audio_dir}/{device}/train/normal_id_0{id}*.wav\"\n",
        "        )\n",
        "        train_normal_files = sorted(glob.glob(query))\n",
        "        train_normal_labels = np.zeros(len(train_normal_files))\n",
        "        \n",
        "        query = os.path.abspath(\n",
        "                f\"{self.audio_dir}/{device}/train/anomaly_id_0{id}*.wav\"\n",
        "            )\n",
        "        train_anomaly_files = sorted(glob.glob(query))\n",
        "        train_anomaly_labels = np.ones(len(train_anomaly_files))\n",
        "        \n",
        "        train_file_list = np.concatenate((train_normal_files, train_anomaly_files), axis=0)\n",
        "        train_labels = np.concatenate((train_normal_labels, train_anomaly_labels), axis=0)\n",
        "        \n",
        "        return train_file_list, train_labels\n",
        "    \n",
        "    def _test_file_list(self, device, id):     \n",
        "        query = os.path.abspath(\n",
        "            f\"{self.audio_dir}/{device}/test/normal_id_0{id}*.wav\"\n",
        "            )\n",
        "        test_normal_files = sorted(glob.glob(query))\n",
        "        test_normal_labels = np.zeros(len(test_normal_files))\n",
        "        \n",
        "        query = os.path.abspath(\n",
        "            f\"{self.audio_dir}/{device}/test/anomaly_id_0{id}*.wav\"\n",
        "            )\n",
        "        test_anomaly_files = sorted(glob.glob(query))\n",
        "        test_anomaly_labels = np.ones(len(test_anomaly_files))\n",
        "        \n",
        "        test_file_list = np.concatenate((test_normal_files, \n",
        "                                          test_anomaly_files), axis=0)\n",
        "        test_labels = np.concatenate((test_normal_labels,\n",
        "                                      test_anomaly_labels), axis=0)\n",
        "          \n",
        "        return test_file_list, test_labels\n",
        "\n",
        "    def normalize(self,tensor):\n",
        "        tensor_minusmean = tensor - tensor.mean()\n",
        "        return tensor_minusmean/np.absolute(tensor_minusmean).max()\n",
        "\n",
        "    def make0min(self,tensornd):\n",
        "        tensor = tensornd.numpy()\n",
        "        res = np.where(tensor == 0, 1E-19 , tensor)\n",
        "        return torch.from_numpy(res)\n",
        "\n",
        "    def spectrogrameToImage(self,specgram):\n",
        "        # specgram = torchaudio.transforms.MelSpectrogram(n_fft=1024, win_length=1024, \n",
        "        #                                                 hop_length=512, power=2, \n",
        "        #                                                 normalized=True, n_mels=128)(waveform )\n",
        "        specgram= self.make0min(specgram)\n",
        "        specgram = specgram.log2()[0,:,:].numpy()\n",
        "        \n",
        "        tr2image = transforms.Compose([transforms.ToPILImage()])\n",
        "\n",
        "        specgram= self.normalize(specgram)\n",
        "        # specgram = img_as_ubyte(specgram)\n",
        "        specgramImage = tr2image(specgram)\n",
        "        return specgramImage\n",
        "\n",
        "    def get_logmelspectrogram(self, waveform):\n",
        "        melspec = librosa.feature.melspectrogram(\n",
        "          n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_length,\n",
        "          power=self.power,n_mels=self.n_mels,pad_mode=self.pad_mode,sr=self.sr,\n",
        "          center=self.center,norm=self.norm,htk=True,\n",
        "          y = waveform.numpy()\n",
        "        )\n",
        "\n",
        "        logmelspec = librosa.power_to_db(melspec)\n",
        "\n",
        "        return logmelspec\n",
        "\n",
        "    def get_melspectrogram(self,waveform):\n",
        "        melspec = librosa.feature.melspectrogram(\n",
        "            n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_length,\n",
        "            power=self.power,n_mels=self.n_mels,pad_mode=self.pad_mode,sr=self.sr,\n",
        "            center=self.center,norm=self.norm,htk=True,\n",
        "            y = waveform.numpy()\n",
        "        )\n",
        "\n",
        "        return melspec\n",
        "    \n",
        "    def get_mfcc(self,waveform):\n",
        "        mfcc = librosa.feature.mfcc(    \n",
        "            n_fft=self.n_fft, win_length=self.win_length, \n",
        "            hop_length=self.hop_length,pad_mode=self.pad_mode,sr=self.sr,\n",
        "            center=self.center,norm=self.norm,n_mfcc=40,\n",
        "            y = waveform.numpy()\n",
        "        )\n",
        "\n",
        "        return mfcc\n",
        "\n",
        "    def get_chroma_stft(self,waveform):\n",
        "        stft = librosa.feature.chroma_stft(\n",
        "            n_fft=self.n_fft, win_length=self.win_length, \n",
        "            hop_length=self.hop_length,pad_mode=self.pad_mode,sr=self.sr,\n",
        "            center=self.center,norm=self.norm,n_chroma=12,\n",
        "            y=waveform.numpy()\n",
        "        )\n",
        "\n",
        "        return stft\n",
        "\n",
        "    def get_spectral_contrast(self,waveform):\n",
        "        spec_contrast = librosa.feature.spectral_contrast(    \n",
        "            n_fft=self.n_fft, win_length=self.win_length,center=self.center,\n",
        "            hop_length=self.hop_length,pad_mode=self.pad_mode,sr=self.sr,\n",
        "            y = waveform.numpy()\n",
        "        )\n",
        "\n",
        "        return spec_contrast\n",
        "    \n",
        "    def get_tonnetz(self,waveform):\n",
        "        harmonic = librosa.effects.harmonic(waveform.numpy())\n",
        "        tonnetz = librosa.feature.tonnetz(y=harmonic,sr=self.sr)\n",
        "\n",
        "        return tonnetz\n",
        "\n",
        "    def get_audios(self, file_list):\n",
        "        data = []\n",
        "        for i in range(len(file_list)):\n",
        "          y, sr = torchaudio.load(file_list[i])  \n",
        "          data.append(y)\n",
        "\n",
        "        return data\n",
        "    def _derive_data(self, file_list):\n",
        "        train_data = []\n",
        "        test_data = []\n",
        "        train_mode = True\n",
        "        for file_list in [self.train_files, self.test_files]:\n",
        "          tr2tensor = transforms.Compose([transforms.PILToTensor()])\n",
        "          data = []\n",
        "          for j in range(len(file_list)):\n",
        "            y, sr = torchaudio.load(file_list[j])  \n",
        "            spec = self.get_melspectrogram(y)\n",
        "            spec = self.spectrogrameToImage(spec)\n",
        "            spec = spec.convert('RGB')\n",
        "            vectors = tr2tensor(spec)\n",
        "            if train_mode:     \n",
        "              train_data.append(vectors)\n",
        "            else:\n",
        "              test_data.append(vectors)\n",
        "            \n",
        "          train_mode = False\n",
        "                \n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S96soeIc0o13"
      },
      "outputs": [],
      "source": [
        "dataset = MimiiDataset('/content/drive/MyDrive/mimii')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Gn2zdn92doi1"
      },
      "outputs": [],
      "source": [
        "_, _, y_train_fan0, y_test_fan0 = dataset.get_data('slider', 0)\n",
        "_, _, y_train_fan2, y_test_fan2 = dataset.get_data('slider', 2)\n",
        "_, _, y_train_fan4, y_test_fan4 = dataset.get_data('slider', 4)\n",
        "_, _, y_train_fan6, y_test_fan6 = dataset.get_data('slider', 6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_mfccs(wave_list):\n",
        "  data = []\n",
        "  for wave in wave_list:\n",
        "    mfcc = np.mean(dataset.get_mfcc(wave)[0], axis = 1)\n",
        "    data.append(mfcc)\n",
        "  \n",
        "  return data\n",
        "\n",
        "def mean_stfts(wave_list):\n",
        "  data = []\n",
        "  for wave in wave_list:\n",
        "    stft = np.mean(dataset.get_chroma_stft(wave)[0], axis = 1)\n",
        "    data.append(stft)\n",
        "  \n",
        "  return data\n",
        "\n",
        "def mean_melspecs(wave_list):\n",
        "  data = []\n",
        "  for wave in wave_list:\n",
        "    melspec = np.mean(dataset.get_melspectrogram(wave)[0], axis = 1)\n",
        "    data.append(melspec)\n",
        "  \n",
        "  return data\n",
        "\n",
        "def mean_spec_contrasts(wave_list):\n",
        "  data = []\n",
        "  for wave in wave_list:\n",
        "    spec_contrast = np.mean(dataset.get_spectral_contrast(wave)[0], axis = 1)\n",
        "    data.append(spec_contrast)\n",
        "  \n",
        "  return data\n",
        "  \n",
        "def mean_tonnetzs(wave_list):\n",
        "  data = []\n",
        "  for wave in wave_list:\n",
        "    tonnetz = np.mean(dataset.get_tonnetz(wave)[0], axis = 1)\n",
        "    data.append(tonnetz)\n",
        "  \n",
        "  return data"
      ],
      "metadata": {
        "id": "quhoMJUJsqyU"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train1, df_test1, y_train1, y_test1 = dataset.get_data('ToyConveyor', 1)\n",
        "# df_train2, df_test2, y_train2, y_test2 = dataset.get_data('ToyConveyor', 2)\n",
        "# df_train3, df_test3, y_train3, y_test3 = dataset.get_data('ToyConveyor', 3)\n",
        "df_train4, df_test4, y_train4, y_test4 = dataset.get_data('ToyConveyor', 4)"
      ],
      "metadata": {
        "id": "C70jD80rrQJ_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_test4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDPZ9Zua5M5C",
        "outputId": "2779c611-4b7a-49b4-8d4f-0ba8ee8ed730"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_melspecs, test_melspecs = mean_melspecs(df_train1), mean_melspecs(df_test1)\n",
        "train_mfccs, test_mfccs = mean_mfccs(df_train1), mean_mfccs(df_test1)\n",
        "train_stfts, test_stfts = mean_stfts(df_train1), mean_stfts(df_test1)\n",
        "train_spec_contrasts, test_spec_contrasts = mean_spec_contrasts(df_train1), mean_spec_contrasts(df_test1)\n",
        "train_tonnetzs, test_tonnetzs = mean_tonnetzs(df_train1), mean_tonnetzs(df_test1)\n",
        "\n",
        "train_mixed_f = []\n",
        "test_mixed_f = []\n",
        "\n",
        "for i in range(len(train_melspecs)):\n",
        "\n",
        "  train_mf = np.concatenate((train_melspecs[i],train_mfccs[i],train_stfts[i],\n",
        "                             train_spec_contrasts[i],train_tonnetzs[i])).tolist()\n",
        "\n",
        "  train_mixed_f.append(train_mf)\n",
        "\n",
        "for i in range(len(test_melspecs)):\n",
        "\n",
        "  test_mf = np.concatenate((test_melspecs[i],test_mfccs[i],test_stfts[i],\n",
        "                             test_spec_contrasts[i],test_tonnetzs[i])).tolist()\n",
        "\n",
        "  test_mixed_f.append(test_mf)\n",
        "\n",
        "train_mixed_f = torch.FloatTensor(train_mixed_f)\n",
        "test_mixed_f = torch.FloatTensor(test_mixed_f)"
      ],
      "metadata": {
        "id": "5NAMxzpLrYJm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(train_mixed_f, '/content/drive/MyDrive/mixed_features/y_tr_toyconveyor1.pt')\n",
        "torch.save(test_mixed_f, '/content/drive/MyDrive/mixed_features/y_ts_toyconveyor1.pt')"
      ],
      "metadata": {
        "id": "sw7SAvRzrmqe"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(torch.FloatTensor(y_train_fan0.tolist()), '/content/drive/MyDrive/labels/y_tr_slider0.pt')\n",
        "torch.save(torch.FloatTensor(y_test_fan0.tolist()), '/content/drive/MyDrive/labels/y_ts_slider0.pt')\n",
        "torch.save(torch.FloatTensor(y_train_fan2.tolist()), '/content/drive/MyDrive/labels/y_tr_slider2.pt')\n",
        "torch.save(torch.FloatTensor(y_test_fan2.tolist()), '/content/drive/MyDrive/labels/y_ts_slider2.pt')\n",
        "torch.save(torch.FloatTensor(y_train_fan4.tolist()), '/content/drive/MyDrive/labels/y_tr_slider4.pt')\n",
        "torch.save(torch.FloatTensor(y_test_fan4.tolist()), '/content/drive/MyDrive/labels/y_ts_slider4.pt')\n",
        "torch.save(torch.FloatTensor(y_train_fan6.tolist()), '/content/drive/MyDrive/labels/y_tr_slider6.pt')\n",
        "torch.save(torch.FloatTensor(y_test_fan6.tolist()), '/content/drive/MyDrive/labels/y_ts_slider6.pt')"
      ],
      "metadata": {
        "id": "BIY-zDvjrIcu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, y_test = torch.load('/content/drive/MyDrive/labels/y_tr_slider0.pt'), torch.load('/content/drive/MyDrive/labels/y_ts_slider0.pt')"
      ],
      "metadata": {
        "id": "siHf9ch8vFoI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mf, test_mf = torch.load('/content/drive/MyDrive/mixed_features/train_mf_slider0.pt'), torch.load('/content/drive/MyDrive/mixed_features/test_mf_slider0.pt')"
      ],
      "metadata": {
        "id": "WiRjmJe_yH6u"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jWMPVGu1qiEq"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader(train_mf, batch_size=64, shuffle = True)\n",
        "test_data = DataLoader(test_mf, batch_size = 64, shuffle= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vNTBTRe6qnBq"
      },
      "outputs": [],
      "source": [
        "class UNet_FC(nn.Module):\n",
        "\n",
        "  def __init__(self, in_features):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.bn = nn.BatchNorm1d(128)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.fc0 = nn.Linear(in_features=in_features,out_features=in_features)\n",
        "\n",
        "    # encoder\n",
        "    self.fc1 = nn.Linear(in_features=in_features, out_features=128)\n",
        "    self.fc2 = nn.Linear(in_features=128,out_features=128)\n",
        "    self.fc3 = nn.Linear(in_features=128, out_features=128)\n",
        "    self.fc4 = nn.Linear(in_features=128, out_features=128)\n",
        "    self.fc5 = nn.Linear(in_features=128, out_features=8)\n",
        "\n",
        "    # decoder\n",
        "    self.fc6 = nn.Linear(in_features=8, out_features=128)\n",
        "    self.fc7 = nn.Linear(in_features=128*2, out_features=128)\n",
        "    self.fc8 = nn.Linear(in_features=128*2, out_features=128)\n",
        "    self.fc9 = nn.Linear(in_features=128*2, out_features=128)\n",
        "\n",
        "    self.out = nn.Linear(in_features=128*2, out_features=in_features)\n",
        "\n",
        "  def encoder(self, x):\n",
        "    input = self.fc0(x)\n",
        "\n",
        "    x1 = self.relu(self.bn(self.fc1(input)))\n",
        "    x2 = self.relu(self.bn(self.fc2(x1)))\n",
        "    x3 = self.relu(self.bn(self.fc3(x2)))\n",
        "    x4 = self.relu(self.bn(self.fc4(x3)))\n",
        "    x5 = self.relu(self.fc5(x4))\n",
        "\n",
        "    return [x5, x4, x3, x2, x1]\n",
        "\n",
        "  def decoder(self, x):\n",
        "    x6 = self.relu(self.fc6(x[0]))\n",
        "    con1 = torch.cat((x6,x[1]), 1) \n",
        "    x7 = self.relu(self.bn(self.fc7(con1)))\n",
        "    con2 = torch.cat((x7,x[2]), 1)\n",
        "    x8 = self.relu(self.bn(self.fc8(con2)))\n",
        "    con3 = torch.cat((x8,x[3]), 1)\n",
        "    x9 = self.relu(self.bn(self.fc9(con3)))\n",
        "    con4 = torch.cat((x9,x[4]), 1)\n",
        "\n",
        "    x10 = self.out(con4)\n",
        "\n",
        "    return x10\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # encoded = self.encoder(x)\n",
        "\n",
        "    # decoded = self.decoder(encoded)\n",
        "    input = self.fc0(x)\n",
        "\n",
        "    x1 = self.relu(self.bn(self.fc1(input)))\n",
        "    x2 = self.relu(self.bn(self.fc2(x1)))\n",
        "    x3 = self.relu(self.bn(self.fc3(x2)))\n",
        "    x4 = self.relu(self.bn(self.fc4(x3)))\n",
        "    x5 = self.relu(self.fc5(x4))\n",
        "\n",
        "    xy = [x5, x4, x3, x2, x1]\n",
        "\n",
        "    x6 = self.relu(self.fc6(xy[0]))\n",
        "    con1 = torch.cat((x6,xy[1]), 1) \n",
        "    x7 = self.relu(self.bn(self.fc7(con1)))\n",
        "    con2 = torch.cat((x7,xy[2]), 1)\n",
        "    x8 = self.relu(self.bn(self.fc8(con2)))\n",
        "    con3 = torch.cat((x8,xy[3]), 1)\n",
        "    x9 = self.relu(self.bn(self.fc9(con3)))\n",
        "    con4 = torch.cat((x9,xy[4]), 1)\n",
        "\n",
        "    x10 = self.out(con4)\n",
        "\n",
        "    # return decoded\n",
        "    return x10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZfgcBtQ3qn5l"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, data_tr, data_val, scheduler = None,\n",
        "          epochs = 3000, device = 'cpu'):\n",
        "    # X_val, Y_val = next(iter(data_val))\n",
        "    losses = []\n",
        "    prev_avg_loss = 100000\n",
        "    for epoch in range(epochs):\n",
        "        train_avg_loss = 0\n",
        "        test_avg_loss = 0\n",
        "        # model.train()  # train mode\n",
        "        for batch in data_tr:\n",
        "          # data to device\n",
        "          batch = batch.to(device)\n",
        "          # set parameter gradients to zero\n",
        "          optimizer.zero_grad()\n",
        "          # forward\n",
        "          # print(Y_batch.shape)\n",
        "          predictions = model(batch)\n",
        "          loss = criterion(predictions, batch)\n",
        "          loss.backward() # backward-pass\n",
        "          optimizer.step()  # update weights\n",
        "          # calculate loss to show the user\n",
        "          if scheduler:\n",
        "            scheduler.step(loss)\n",
        "          train_avg_loss += loss / len(data_tr)\n",
        "\n",
        "        # model.eval()\n",
        "        for batch in data_val:\n",
        "          with torch.no_grad():\n",
        "            preds = model(batch.to(device)).cpu()\n",
        "            loss = criterion(preds,batch)\n",
        "            test_avg_loss += loss / len(data_val)\n",
        "                    \n",
        "        losses.append(train_avg_loss.item())\n",
        "        if (epoch+1)%100 == 0:\n",
        "          print(\"{}/{} train_loss: {} test_loss:{}\".format(epoch+1, epochs, train_avg_loss, test_avg_loss))\n",
        "        # if test_avg_loss < 70:\n",
        "        #   break\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ptkVTF55quOL"
      },
      "outputs": [],
      "source": [
        "unet = UNet_FC(in_features=193).to(device)\n",
        "optimizer = Adam(params = unet.parameters(), lr = 10e-3)\n",
        "# optimizer = Adam(params = unet.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, \n",
        "                                                       min_lr=10e-4, mode = 'min',\n",
        "                                                       patience = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkfmYl9oXhcB",
        "outputId": "85710d25-0f9f-46fc-963d-89021c656ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/3000 train_loss: 548.6768188476562 test_loss:3930.87841796875\n",
            "200/3000 train_loss: 373.0775451660156 test_loss:3878.34326171875\n",
            "300/3000 train_loss: 250.9510498046875 test_loss:3912.1787109375\n",
            "400/3000 train_loss: 226.56639099121094 test_loss:3917.408203125\n",
            "500/3000 train_loss: 176.40565490722656 test_loss:3743.869873046875\n",
            "600/3000 train_loss: 144.66822814941406 test_loss:3580.272216796875\n",
            "700/3000 train_loss: 126.55216979980469 test_loss:3696.25244140625\n",
            "800/3000 train_loss: 113.44833374023438 test_loss:3564.515380859375\n",
            "900/3000 train_loss: 98.3164291381836 test_loss:3522.873291015625\n",
            "1000/3000 train_loss: 93.22779846191406 test_loss:3508.326904296875\n",
            "1100/3000 train_loss: 86.74024963378906 test_loss:3435.44775390625\n",
            "1200/3000 train_loss: 71.61650848388672 test_loss:3583.8994140625\n",
            "1300/3000 train_loss: 71.25789642333984 test_loss:3567.39306640625\n",
            "1400/3000 train_loss: 63.721744537353516 test_loss:3679.42431640625\n",
            "1500/3000 train_loss: 58.28046417236328 test_loss:3507.9091796875\n",
            "1600/3000 train_loss: 54.829620361328125 test_loss:3740.91259765625\n",
            "1700/3000 train_loss: 47.95491409301758 test_loss:3549.314697265625\n",
            "1800/3000 train_loss: 47.211971282958984 test_loss:3587.352783203125\n",
            "1900/3000 train_loss: 52.88410949707031 test_loss:3487.288330078125\n",
            "2000/3000 train_loss: 47.206077575683594 test_loss:3534.90576171875\n",
            "2100/3000 train_loss: 47.95636749267578 test_loss:3633.59033203125\n",
            "2200/3000 train_loss: 42.30171585083008 test_loss:3427.034912109375\n",
            "2300/3000 train_loss: 44.05908203125 test_loss:3531.48388671875\n",
            "2400/3000 train_loss: 40.84529113769531 test_loss:3384.62744140625\n",
            "2500/3000 train_loss: 38.191680908203125 test_loss:3429.567626953125\n",
            "2600/3000 train_loss: 44.47454071044922 test_loss:3450.49755859375\n",
            "2700/3000 train_loss: 37.616703033447266 test_loss:3514.69384765625\n",
            "2800/3000 train_loss: 38.55052185058594 test_loss:3453.939697265625\n",
            "2900/3000 train_loss: 44.5402717590332 test_loss:3469.560546875\n",
            "3000/3000 train_loss: 34.25009536743164 test_loss:3537.027099609375\n"
          ]
        }
      ],
      "source": [
        "losses= train(model = unet, optimizer = optimizer, criterion=criterion, data_tr=train_data,\n",
        "               data_val = test_data, scheduler = scheduler, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ew7_F0-q7aL",
        "outputId": "ea138799-0853-4ce6-9fd9-34b3b5cc9ac9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3537.0271)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "avg_loss = 0\n",
        "# unet.eval()\n",
        "# unet.train()\n",
        "preds = []\n",
        "i = 0\n",
        "test_anomaly_losses = []\n",
        "test_normal_losses = []\n",
        "test_losses = []\n",
        "# test_real = y_test_fan0.tolist()\n",
        "# y_test_fan0 = y_test_fan0.tolist()\n",
        "for batch in test_data:\n",
        "  with torch.no_grad():\n",
        "    # unet.train()\n",
        "    predictions = unet(batch.to(device)).cpu()\n",
        "    preds.append(predictions)\n",
        "  loss = criterion(predictions, batch.cpu())\n",
        "  for j in range(len(predictions)):\n",
        "    if int(y_test[i]) == 1:\n",
        "      test_anomaly_losses.append(float(criterion(predictions[j], batch[j])))\n",
        "    else:\n",
        "      test_normal_losses.append(float(criterion(predictions[j], batch[j])))\n",
        "    i += 1\n",
        "    test_losses.append(criterion(predictions[j], batch[j]))\n",
        "  # print(loss)\n",
        "  # print(loss)\n",
        "  avg_loss += loss / len(test_data)\n",
        "# avg_loss\n",
        "\n",
        "avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpDKorrRso9o",
        "outputId": "5385ccd6-6f54-4af8-f125-9fb386a05566"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4364.920546542393, 217.59184698104858)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "sum(test_anomaly_losses)/len(test_anomaly_losses) , sum(test_normal_losses)/len(test_normal_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cJE0-57Qts3E"
      },
      "outputs": [],
      "source": [
        "# torch.save(unet, \"unet_fan2_2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDIzf9t_H3pt",
        "outputId": "aa541b05-660b-41b5-c4e3-7349e310763e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LEvbZKYuh7J",
        "outputId": "ee4c6e6f-1e9a-45f2-f669-a4e31020145d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9705056179775281\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "vals = np.arange(40, 900, 0.5).tolist()\n",
        "for threshold in vals:\n",
        "  preds = []\n",
        "  for j in range(len(test_losses)):\n",
        "    if test_losses[j] > threshold:\n",
        "      preds.append(1)\n",
        "    else:\n",
        "      preds.append(0)\n",
        "  \n",
        "  results.append(roc_auc_score(y_test,preds))\n",
        "\n",
        "print(max(results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4H4vpFX35yK"
      },
      "outputs": [],
      "source": [
        "def get_logmelspectrogram(waveform):\n",
        "    melspec = librosa.feature.melspectrogram(y=waveform.numpy(), hop_length=250, n_mels = 304)\n",
        "\n",
        "    logmelspec = librosa.power_to_db(melspec)\n",
        "\n",
        "    return logmelspec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo1-S_qcuUZR"
      },
      "outputs": [],
      "source": [
        "# train_logmelspecs, test_logmelspecs = mean_logmelspecs(df_train), mean_logmelspecs(df_test)\n",
        "train_data1 = []\n",
        "for wave in df_train:\n",
        "  train_data1.append(get_logmelspectrogram(wave)[0])\n",
        "\n",
        "test_data1 = []\n",
        "for wave in df_test:\n",
        "  test_data1.append(get_logmelspectrogram(wave)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGd9oI5IEVMx",
        "outputId": "73a79d4e-9e50-4b29-e7ea-55ee60a08c22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-30-68ec04120629>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  train_data1 = torch.FloatTensor(train_data1)\n"
          ]
        }
      ],
      "source": [
        "train_data1 = torch.FloatTensor(train_data1)\n",
        "test_data1 = torch.FloatTensor(test_data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMOi9331OVb4"
      },
      "outputs": [],
      "source": [
        "train_logs = DataLoader(train_data1.reshape(916*304,641),batch_size = 304)\n",
        "test_logs = DataLoader(test_data1.reshape(459*304,641),batch_size = 304)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9rD6tuI1rfe"
      },
      "outputs": [],
      "source": [
        "unet1 = UNet_FC(in_features=641).to(device)\n",
        "optimizer1 = Adam(params = unet1.parameters(), lr = 10e-3)\n",
        "# optimizer = Adam(params = unet.parameters())\n",
        "criterion1 = nn.MSELoss()\n",
        "scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer1, factor=0.5, \n",
        "                                                       min_lr=10e-4, mode = 'min',\n",
        "                                                       patience = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr6k85ma3ftD",
        "outputId": "67174f45-79f9-41f1-8959-a0c75a2b17fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 train_loss: 21.703369140625 test_loss:17.446470260620117\n"
          ]
        }
      ],
      "source": [
        "losses = train(model = unet1, optimizer = optimizer1, criterion=criterion1, data_tr=train_logs,\n",
        "               data_val = test_logs, device = device, epochs = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrPbpKgSPx7v",
        "outputId": "a7bd10e8-e2bd-4579-8211-d6eaaa879711"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(17.4465)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "avg_loss = 0\n",
        "# unet.eval()\n",
        "# unet.train()\n",
        "preds = []\n",
        "i = 0\n",
        "test_anomaly_losses = []\n",
        "test_normal_losses = []\n",
        "test_losses = []\n",
        "test_real = y_test.tolist()\n",
        "for batch in test_logs:\n",
        "  with torch.no_grad():\n",
        "    # unet.train()\n",
        "    predictions = unet1(batch.to(device)).cpu()\n",
        "    preds.append(predictions)\n",
        "    loss = criterion(predictions, batch.cpu())\n",
        "    test_losses.append(loss)\n",
        "    if int(y_test[i]) == 1:\n",
        "      test_anomaly_losses.append(loss)\n",
        "    else:\n",
        "      test_normal_losses.append(loss)\n",
        "    i += 1\n",
        "  # print(loss)\n",
        "  # print(loss)\n",
        "  avg_loss += loss / len(test_logs)\n",
        "# avg_loss\n",
        "\n",
        "avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z5Z1XYFN_x2",
        "outputId": "9d767817-5525-443f-db72-2588edb4cfbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(18.0466), tensor(15.2920))"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(test_anomaly_losses)/len(test_anomaly_losses) , sum(test_normal_losses)/len(test_normal_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er74WfG7P_B1",
        "outputId": "884ef8f3-8bfe-4d71-bc01-534f5d5a0a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5875626740947075\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "vals = np.arange(10, 21, 0.1).tolist()\n",
        "for threshold in vals:\n",
        "  preds = []\n",
        "  for j in range(len(test_losses)):\n",
        "    if test_losses[j] > threshold:\n",
        "      preds.append(1)\n",
        "    else:\n",
        "      preds.append(0)\n",
        "  \n",
        "  results.append(roc_auc_score(test_real,preds))\n",
        "\n",
        "print(max(results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaSSqG8SbAw2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}